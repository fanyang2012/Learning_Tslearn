机器学习模型可解释性

https://www.zhihu.com/question/48224234







shap

http://sofasofa.io/tutorials/shap_xgboost/

SHAP value 的解释：SHAP值通过与某一特征取基线值时的预测做对比，来解释该特征取某一特定值的影响。





作用：

特征重要性，

单一样本各个特征的重要性

特征交互





**partial dependence**

部分依赖图（PDP或PD图）显示特征对机器学习模型的预测结果的边际效应，可以展示一个特征是如何影响预测的。部分依赖图可以显示目标与特征之间的关系是线性的，单调的还是更复杂的。例如，当应用于线性回归模型时，部分依赖图总是显示线性关系。



**PDP分析步骤如下：**

1. 训练一个Xgboost模型（假设F1 … F4是我们的特征，Y是目标变量，假设F1是最重要的特征）。
2. 我们有兴趣探索Y和F1的直接关系。
3. 用F1（A）代替F1列，并为所有的观察找到新的预测值。采取预测的平均值。（称之为基准值）
4. 对F1（B）… F1（E）重复步骤3，即针对特征F1的所有不同值。
5. PDP的X轴具有不同的F1值，而Y轴是虽该基准值F1值的平均预测而变化。







eli5

https://www.sohu.com/a/324334904_114877



# 排列重要性

**Permutation Importance**



#### PI思想

- 用上全部特征，训练一个模型。
- 验证集预测得到得分。
- 验证集的一个特征列的值进行随机打乱，预测得到得分。
- 将上述得分做差即可得到特征x1对预测的影响。
- 依次将每一列特征按上述方法做，得到每二个特征对预测的影响。



